{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d2a97ae9",
   "metadata": {},
   "source": [
    "### An example in finetuning\n",
    "Using Hugging Face for data\n",
    "\n",
    "Required reading: https://karpathy.github.io/2019/04/25/recipe/ - \"A recipe for training neural networks\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2513254e",
   "metadata": {},
   "source": [
    "#### Become one with the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b72fcf98",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jenniferjordache/Developer/core-knowledge-ml/myenv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import random\n",
    "import pandas as pd\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, Trainer, TrainingArguments\n",
    "from pprint import pprint\n",
    "\n",
    "def set_seed(seed=42):\n",
    "    random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "\n",
    "set_seed()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "109a75d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset, Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aea3accf",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset(\"stanfordnlp/imdb\")\n",
    "train_df = dataset[\"train\"].to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "37e7142a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['dataset'] = 'train'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8856855f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                text  label dataset\n",
      "0  I rented I AM CURIOUS-YELLOW from my video sto...      0   train\n",
      "1  \"I Am Curious: Yellow\" is a risible and preten...      0   train\n",
      "2  If only to avoid making this type of film in t...      0   train\n",
      "3  This film was probably inspired by Godard's Ma...      0   train\n",
      "4  Oh, brother...after hearing about this ridicul...      0   train\n",
      "Number of null values:\n",
      "text       0\n",
      "label      0\n",
      "dataset    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(train_df.head())\n",
    "print(\"Number of null values:\")\n",
    "print(train_df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "59be843d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataframe Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 25000 entries, 0 to 24999\n",
      "Data columns (total 3 columns):\n",
      " #   Column   Non-Null Count  Dtype \n",
      "---  ------   --------------  ----- \n",
      " 0   text     25000 non-null  object\n",
      " 1   label    25000 non-null  int64 \n",
      " 2   dataset  25000 non-null  object\n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 586.1+ KB\n",
      "None\n",
      "\n",
      "\n",
      "Dataframe Description:\n",
      "             label\n",
      "count  25000.00000\n",
      "mean       0.50000\n",
      "std        0.50001\n",
      "min        0.00000\n",
      "25%        0.00000\n",
      "50%        0.50000\n",
      "75%        1.00000\n",
      "max        1.00000\n",
      "\n",
      "\n",
      "Number of unique values in each column:\n",
      "text       24904\n",
      "label          2\n",
      "dataset        1\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"Dataframe Info:\")\n",
    "print(train_df.info())\n",
    "print(\"\\n\")\n",
    "print(\"Dataframe Description:\")\n",
    "print(train_df.describe())\n",
    "print(\"\\n\")\n",
    "print(\"Number of unique values in each column:\")\n",
    "print(train_df.nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "914b866e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Arguably this is a very good \"sequel\", better than the first live action '\n",
      " 'film 101 Dalmatians. It has good dogs, good actors, good jokes and all right '\n",
      " 'slapstick! <br /><br />Cruella DeVil, who has had some rather major therapy, '\n",
      " 'is now a lover of dogs and very kind to them. Many, including Chloe Simon, '\n",
      " 'owner of one of the dogs that Cruella once tried to kill, do not believe '\n",
      " 'this. Others, like Kevin Shepherd (owner of 2nd Chance Dog Shelter) believe '\n",
      " 'that she has changed. <br /><br />Meanwhile, Dipstick, with his mate, have '\n",
      " 'given birth to three cute dalmatian puppies! Little Dipper, Domino and '\n",
      " 'Oddball...<br /><br />Starring Eric Idle as Waddlesworth (the hilarious '\n",
      " 'macaw), Glenn Close as Cruella herself and Gerard Depardieu as Le Pelt '\n",
      " '(another baddie, the name should give a clue), this is a good family film '\n",
      " 'with excitement and lots more!! One downfall of this film is that is has a '\n",
      " 'lot of painful slapstick, but not quite as excessive as the last film. This '\n",
      " 'is also funnier than the last film.<br /><br />Enjoy \"102 Dalmatians\"! :-)')\n"
     ]
    }
   ],
   "source": [
    "random_index = random.randint(0, len(train_df) - 1)\n",
    "pprint(train_df.loc[random_index, 'text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "57757b9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (720 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shortest review length (in tokens): 13\n",
      "Longest review length (in tokens): 3127\n",
      "Average review length (in tokens): 313.87132\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
    "tokenized_reviews = train_df['text'].apply(lambda x: tokenizer.encode(x, add_special_tokens=True))\n",
    "review_token_lengths = tokenized_reviews.apply(len)\n",
    "print(f\"Shortest review length (in tokens): {review_token_lengths.min()}\")\n",
    "print(f\"Longest review length (in tokens): {review_token_lengths.max()}\")\n",
    "print(f\"Average review length (in tokens): {review_token_lengths.mean()}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e5fa824",
   "metadata": {},
   "source": [
    "We'll need to be careful with how we handle the longer reviews in the dataset given the warning message above"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b33191ec",
   "metadata": {},
   "source": [
    "#### Get baselines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4f97f147",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = Dataset.from_pandas(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "af30479b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 25000/25000 [00:10<00:00, 2375.22 examples/s]\n"
     ]
    }
   ],
   "source": [
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples['text'], padding=\"longest\", truncation=True)\n",
    "\n",
    "tokenized_train_dataset = train_dataset.map(tokenize_function, batched=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "93462264",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at prajjwal1/bert-tiny and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained(\"prajjwal1/bert-tiny\", num_labels=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fe5210e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = dataset[\"test\"].to_pandas()\n",
    "test_df['dataset'] = 'test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e7be0a2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 25000/25000 [00:10<00:00, 2385.44 examples/s]\n"
     ]
    }
   ],
   "source": [
    "test_dataset = Dataset.from_pandas(test_df)\n",
    "tokenized_test_dataset = test_dataset.map(tokenize_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6af0e3ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3125/3125 [01:35<00:00, 32.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.7193034291267395, 'eval_runtime': 101.787, 'eval_samples_per_second': 245.611, 'eval_steps_per_second': 30.701}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir='./temp_results',  \n",
    "    do_train=False,\n",
    "    do_eval=True,\n",
    "    seed=42\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    eval_dataset=tokenized_test_dataset\n",
    ")\n",
    "\n",
    "test_results = trainer.evaluate()\n",
    "print(test_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d89dc4fa",
   "metadata": {},
   "source": [
    "#### Padding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5df5e17f",
   "metadata": {},
   "source": [
    "When feeding examples to a model during training, we typically feed them in as batches so they can be processed in parallel, saving time. If different examples in a batch are of different lengths, this parallel operation is not possible, forcing us to process each sequence individually. To force all examples in a batch to be the same length, we use padding and truncation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bd1cb3bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original text: I am a short sentence.\n",
      "Tokenized text: [101, 1045, 2572, 1037, 2460, 6251, 1012, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "\n",
      "\n",
      "Original text: I am a medium sentence. Not too long, not too short.\n",
      "Tokenized text: [101, 1045, 2572, 1037, 5396, 6251, 1012, 2025, 2205, 2146, 1010, 2025, 2205, 2460, 1012, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "\n",
      "\n",
      "Original text: I am an exceedingly longwinded, verbose, talks-a-lot, redundant sentence that can't stop running on and on and on.\n",
      "Tokenized text: [101, 1045, 2572, 2019, 17003, 2135, 2146, 11101, 2098, 1010, 12034, 9232, 1010, 7566, 1011, 1037, 1011, 2843, 1010, 21707, 6251, 2008, 2064, 1005, 1056, 2644, 2770, 2006, 1998, 2006, 1998, 2006, 1012, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "example_texts = [\"I am a short sentence.\", \"I am a medium sentence. Not too long, not too short.\", \"I am an exceedingly longwinded, verbose, talks-a-lot, redundant sentence that can't stop running on and on and on.\"]\n",
    "\n",
    "fixed_length_tokens = []\n",
    "for text in example_texts:\n",
    "    tokenized_text = tokenizer(text, padding=\"max_length\", max_length=50)\n",
    "    fixed_length_tokens.append(tokenized_text)\n",
    "\n",
    "for i in range(3):\n",
    "    print(f\"Original text: {example_texts[i]}\")\n",
    "    print(f\"Tokenized text: {fixed_length_tokens[i]['input_ids']}\")\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "378e522f",
   "metadata": {},
   "source": [
    "Super inefficient to use max padding, better to use dynamic padding where each example in the batch is padded out to the length of the longest sequence in the batch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "108b5371",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original text: I am a short sentence.\n",
      "Tokenized text: [101, 1045, 2572, 1037, 2460, 6251, 1012, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Length of tokenized text: 34\n",
      "\n",
      "\n",
      "Original text: I am a medium sentence. Not too long, not too short.\n",
      "Tokenized text: [101, 1045, 2572, 1037, 5396, 6251, 1012, 2025, 2205, 2146, 1010, 2025, 2205, 2460, 1012, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Length of tokenized text: 34\n",
      "\n",
      "\n",
      "Original text: I am an exceedingly longwinded, verbose, talks-a-lot, redundant sentence that can't stop running on and on and on.\n",
      "Tokenized text: [101, 1045, 2572, 2019, 17003, 2135, 2146, 11101, 2098, 1010, 12034, 9232, 1010, 7566, 1011, 1037, 1011, 2843, 1010, 21707, 6251, 2008, 2064, 1005, 1056, 2644, 2770, 2006, 1998, 2006, 1998, 2006, 1012, 102]\n",
      "Length of tokenized text: 34\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dynamically_padded = tokenizer(example_texts, padding='longest')\n",
    "\n",
    "for i in range(3):\n",
    "    print(f\"Original text: {example_texts[i]}\")\n",
    "    print(f\"Tokenized text: {dynamically_padded['input_ids'][i]}\")\n",
    "    print(f\"Length of tokenized text: {len(dynamically_padded['input_ids'][i])}\")\n",
    "    print(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a5c1c1d",
   "metadata": {},
   "source": [
    "#### Truncation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "701be224",
   "metadata": {},
   "source": [
    "Truncation is used to cut off sentences that we decide are too long. The default truncation setting when True is to truncate to the longest length permitted by the model. However, we can also set a max length to truncate to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c29a5ac3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of non-truncated tokens:\n",
      "Text 1: 8\n",
      "Text 2: 16\n",
      "Text 3: 34\n",
      "Length of default truncated tokens:\n",
      "Text 1: 8\n",
      "Text 2: 16\n",
      "Text 3: 34\n",
      "Length of truncated tokens when max_length = 5:\n",
      "Text 1: 5\n",
      "Text 2: 5\n",
      "Text 3: 5\n"
     ]
    }
   ],
   "source": [
    "tokenized_no_truncation = tokenizer(example_texts, truncation=False)\n",
    "print(\"Length of non-truncated tokens:\")\n",
    "for idx, tok in enumerate(tokenized_no_truncation['input_ids']):\n",
    "    print(f\"Text {idx+1}: {len(tok)}\")\n",
    "\n",
    "tokenized_default_truncation = tokenizer(example_texts, truncation=True)\n",
    "print(\"Length of default truncated tokens:\")\n",
    "for idx, tok in enumerate(tokenized_default_truncation['input_ids']):\n",
    "    print(f\"Text {idx+1}: {len(tok)}\")\n",
    "\n",
    "tokenized_max_length = tokenizer(example_texts, truncation=True, max_length=5)\n",
    "print(\"Length of truncated tokens when max_length = 5:\")\n",
    "for idx, tok in enumerate(tokenized_max_length['input_ids']):\n",
    "    print(f\"Text {idx+1}: {len(tok)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f105603a",
   "metadata": {},
   "source": [
    "The rest of the finetuning process will be done in Google colab in order to access GPUs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37470fd9",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
